{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mske80S67Zlm"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "\n",
        "# Kindly add all your installations and versions if any in this cell."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import csv\n",
        "from scipy import stats\n",
        "from sklearn import linear_model\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, losses, models, util\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.readers import InputExample\n",
        "\n",
        "import torch \n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "vphxW0e_8Uza"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import SnowballStemmer\n",
        "import re\n",
        "from gensim import utils\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSe1X18NPakY",
        "outputId": "7b1f2c3a-9ee1-4158-c6ef-b919b1aa20cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH=\"drive/MyDrive/NLP Ass3 stsbenchmark/\"\n",
        "def read_sts_csv(dataset_type=\"train\", columns=['source', 'type', 'year', 'id', 'score', 'sent_a', 'sent_b']):\n",
        "  path = INPUT_PATH + \"sts-\"+ dataset_type + \".csv\"\n",
        "  return pd.read_csv(path,sep=\"\\t\",header=None, names=columns,quoting=csv.QUOTE_NONE)\n",
        "\n",
        "data_train = read_sts_csv(\"train\") # create the train, dev and test dataframes\n",
        "data_dev = read_sts_csv(\"dev\") # create the train, dev and test dataframes\n",
        "data_test = read_sts_csv(\"test\") # create the train, dev and test dataframes\n",
        "\n",
        "final_data=data_train.copy(deep=True)\n",
        "print(len(data_train))\n",
        "final_data=final_data.append(data_dev,ignore_index=True)\n",
        "print(len(data_dev))\n",
        "final_data=final_data.append(data_test,ignore_index=True)\n",
        "print(len(data_test))\n"
      ],
      "metadata": {
        "id": "20F3h1rj8U2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573324e6-3486-4870-c288-1de2d0ba95ea"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5749\n",
            "1500\n",
            "1379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(final_data))\n",
        "final_data\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "ZZQ9-kj1-CVt",
        "outputId": "8722bf60-7ac8-4d89-ef87-69c537a51093"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8628\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             source       type      year    id  score  \\\n",
              "0     main-captions     MSRvid  2012test     1   5.00   \n",
              "1     main-captions     MSRvid  2012test     4   3.80   \n",
              "2     main-captions     MSRvid  2012test     5   3.80   \n",
              "3     main-captions     MSRvid  2012test     6   2.60   \n",
              "4     main-captions     MSRvid  2012test     9   4.25   \n",
              "...             ...        ...       ...   ...    ...   \n",
              "8623      main-news  headlines      2016  1354   0.00   \n",
              "8624      main-news  headlines      2016  1360   1.00   \n",
              "8625      main-news  headlines      2016  1368   1.00   \n",
              "8626      main-news  headlines      2016  1420   0.00   \n",
              "8627      main-news  headlines      2016  1432   0.00   \n",
              "\n",
              "                                                 sent_a  \\\n",
              "0                                A plane is taking off.   \n",
              "1                       A man is playing a large flute.   \n",
              "2         A man is spreading shreded cheese on a pizza.   \n",
              "3                          Three men are playing chess.   \n",
              "4                           A man is playing the cello.   \n",
              "...                                                 ...   \n",
              "8623  Philippines, Canada pledge to further boost re...   \n",
              "8624  Israel bars Palestinians from Jerusalem's Old ...   \n",
              "8625         How much do you know about Secret Service?   \n",
              "8626  Obama Struggles to Soothe Saudi Fears As Iran ...   \n",
              "8627          South Korea declares end to MERS outbreak   \n",
              "\n",
              "                                                 sent_b  \n",
              "0                           An air plane is taking off.  \n",
              "1                             A man is playing a flute.  \n",
              "2     A man is spreading shredded cheese on an uncoo...  \n",
              "3                            Two men are playing chess.  \n",
              "4                    A man seated is playing the cello.  \n",
              "...                                                 ...  \n",
              "8623            Philippines saves 100 after ferry sinks  \n",
              "8624  Two-state solution between Palestinians, Israe...  \n",
              "8625  Lawmakers from both sides express outrage at S...  \n",
              "8626  Myanmar Struggles to Finalize Voter Lists for ...  \n",
              "8627  North Korea Delegation Meets With South Korean...  \n",
              "\n",
              "[8628 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1842dfd7-a7fd-4ef4-a66a-eedea205a10b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>type</th>\n",
              "      <th>year</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>sent_a</th>\n",
              "      <th>sent_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>1</td>\n",
              "      <td>5.00</td>\n",
              "      <td>A plane is taking off.</td>\n",
              "      <td>An air plane is taking off.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>4</td>\n",
              "      <td>3.80</td>\n",
              "      <td>A man is playing a large flute.</td>\n",
              "      <td>A man is playing a flute.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>5</td>\n",
              "      <td>3.80</td>\n",
              "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
              "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>6</td>\n",
              "      <td>2.60</td>\n",
              "      <td>Three men are playing chess.</td>\n",
              "      <td>Two men are playing chess.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>9</td>\n",
              "      <td>4.25</td>\n",
              "      <td>A man is playing the cello.</td>\n",
              "      <td>A man seated is playing the cello.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8623</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1354</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Philippines, Canada pledge to further boost re...</td>\n",
              "      <td>Philippines saves 100 after ferry sinks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8624</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1360</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Israel bars Palestinians from Jerusalem's Old ...</td>\n",
              "      <td>Two-state solution between Palestinians, Israe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8625</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1368</td>\n",
              "      <td>1.00</td>\n",
              "      <td>How much do you know about Secret Service?</td>\n",
              "      <td>Lawmakers from both sides express outrage at S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8626</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1420</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Obama Struggles to Soothe Saudi Fears As Iran ...</td>\n",
              "      <td>Myanmar Struggles to Finalize Voter Lists for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8627</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1432</td>\n",
              "      <td>0.00</td>\n",
              "      <td>South Korea declares end to MERS outbreak</td>\n",
              "      <td>North Korea Delegation Meets With South Korean...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8628 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1842dfd7-a7fd-4ef4-a66a-eedea205a10b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1842dfd7-a7fd-4ef4-a66a-eedea205a10b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1842dfd7-a7fd-4ef4-a66a-eedea205a10b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h3wBUu_-BoQ",
        "outputId": "726fa842-158d-4bd6-9cbc-70be7b03fa5f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source    0\n",
              "type      0\n",
              "year      0\n",
              "id        0\n",
              "score     0\n",
              "sent_a    0\n",
              "sent_b    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic6uC4dw-BvB",
        "outputId": "63f4dc49-5edf-4b40-ae72-f13178451ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def review_to_wordlist(review, remove_stopwords=True):\n",
        "    # Clean the text, with the option to remove stopwords.\n",
        "    \n",
        "    # Convert words to lower case and split them\n",
        "    words = review.lower().split()\n",
        "\n",
        "    # Optionally remove stop words (true by default)\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    \n",
        "    review_text = \" \".join(words)\n",
        "\n",
        "    # Clean the text\n",
        "    review_text = re.sub(r\"[^A-Za-z0-9(),!.?\\'\\`]\", \" \", review_text)\n",
        "    review_text = re.sub(r\"\\'s\", \" 's \", review_text)\n",
        "    review_text = re.sub(r\"\\'ve\", \" 've \", review_text)\n",
        "    review_text = re.sub(r\"n\\'t\", \" 't \", review_text)\n",
        "    review_text = re.sub(r\"\\'re\", \" 're \", review_text)\n",
        "    review_text = re.sub(r\"\\'d\", \" 'd \", review_text)\n",
        "    review_text = re.sub(r\"\\'ll\", \" 'll \", review_text)\n",
        "    review_text = re.sub(r\",\", \" \", review_text)\n",
        "    review_text = re.sub(r\"\\.\", \" \", review_text)\n",
        "    review_text = re.sub(r\"!\", \" \", review_text)\n",
        "    review_text = re.sub(r\"\\(\", \" ( \", review_text)\n",
        "    review_text = re.sub(r\"\\)\", \" ) \", review_text)\n",
        "    review_text = re.sub(r\"\\?\", \" \", review_text)\n",
        "    review_text = re.sub(r\"\\s{2,}\", \" \", review_text)\n",
        "    \n",
        "    words = review_text.split()\n",
        "    \n",
        "    # Shorten words to their stems\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    \n",
        "    review_text = \" \".join(stemmed_words)\n",
        "    \n",
        "    # Return a list of words\n",
        "    # print(review_text)\n",
        "    return(review_text)"
      ],
      "metadata": {
        "id": "CXi3pKVxQuUf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1=[]\n",
        "list2=[]\n",
        "for i in final_data['sent_a']:\n",
        "  list1.append(review_to_wordlist(i))\n",
        "final_data['sent_a']=list1\n",
        "for i in final_data['sent_b']:\n",
        "  list2.append(review_to_wordlist(i))\n",
        "final_data['sent_b']=list2"
      ],
      "metadata": {
        "id": "905KAXFYRAaF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data['sent_a'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FEMHEpilRAjt",
        "outputId": "ff8f8fc8-f5ae-48b9-fe49-9260fb3e2cc7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'man play larg flute'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contains the processed questions for Doc2Vec\n",
        "sent_labeled = []\n",
        "\n",
        "for i in range(len(final_data['sent_a'])):\n",
        "    # Question strings need to be separated into words\n",
        "    # Each question needs a unique label\n",
        "    sent_labeled.append(LabeledSentence(final_data['sent_a'][i].split(), final_data[final_data.index == i].id))\n",
        "    sent_labeled.append(LabeledSentence(final_data['sent_b'][i].split(), final_data[final_data.index == i].id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxX29Z7TWb2L",
        "outputId": "4f64121b-ba60-4136-e893-ffe4beb4bc1f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-0c4749e6b197>:7: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
            "  sent_labeled.append(LabeledSentence(final_data['sent_a'][i].split(), final_data[final_data.index == i].id))\n",
            "<ipython-input-48-0c4749e6b197>:8: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
            "  sent_labeled.append(LabeledSentence(final_data['sent_b'][i].split(), final_data[final_data.index == i].id))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sent_labeled[5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rvmR33ojlLw",
        "outputId": "0256ed0f-f907-4d0b-c3cb-5ff83981c7bb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LabeledSentence(['protest', 'rush', 'stage', 'twice', 'cut', 'power', 'microphon', 'hedg', 'drew', 'speech', 'earli', 'close'], 2500    81\n",
            "Name: id, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(dm = 1, min_count=1, window=10, size=150, sample=1e-4, negative=10)\n",
        "model.build_vocab(sent_labeled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-YRLCh9U0wO",
        "outputId": "8a537efa-63d9-45a0-a639-8817881a58fd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 epochs performs a bit better, but timed out when uploading\n",
        "# for epoch in range(5):\n",
        "    # model.train(sent_labeled)\n",
        "model.train(sent_labeled, total_examples=model.corpus_count, epochs=200)\n",
        "    # print(\"Epoch #{} is complete.\".format(epoch+1))"
      ],
      "metadata": {
        "id": "3hQL-WygU0y0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.most_similar('smoke')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF0gv07gU09k",
        "outputId": "67a29bde-1415-41e8-d68d-e21c54cbf170"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-2d707f8dacca>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  model.most_similar('smoke')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('exempt', 0.8672272562980652),\n",
              " ('patron', 0.8593421578407288),\n",
              " ('hubbard', 0.8487163782119751),\n",
              " ('defec', 0.8383276462554932),\n",
              " ('compost', 0.8358578681945801),\n",
              " ('litterbox', 0.8344850540161133),\n",
              " ('subvers', 0.8289760947227478),\n",
              " ('galant', 0.8253263831138611),\n",
              " ('neurolog', 0.823425829410553),\n",
              " ('wrinkl', 0.8227075934410095)]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sent_labeled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eInNzKQMd-iE",
        "outputId": "d2ac3ad6-25de-4bf2-a6cc-dfd9232b7996"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sent_a_split = []\n",
        "for i in range(len(data_train['sent_a'])):\n",
        "    sent_a_split.append(final_data['sent_a'][i].split())\n",
        "    \n",
        "sent_b_split = []\n",
        "for i in range(len(data_train['sent_b'])):\n",
        "    sent_b_split.append(final_data['sent_b'][i].split())"
      ],
      "metadata": {
        "id": "loUC0cAB-qks"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sent_a_split_test = []\n",
        "for i in range(7249, len(final_data['sent_a'])):\n",
        "    sent_a_split_test.append(final_data['sent_a'][i].split())\n",
        "    \n",
        "sent_b_split_test = []\n",
        "for i in range(7249, len(final_data['sent_b'])):\n",
        "    sent_b_split_test.append(final_data['sent_b'][i].split())"
      ],
      "metadata": {
        "id": "Fa32xW7yCovC"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(final_data['sent_b']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq-Mly_fBk-1",
        "outputId": "213e2d4a-50ee-4373-b772-1cbdf5853b70"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2vec_scores = []\n",
        "for i in range(len(sent_a_split)):\n",
        "    # n_similarity computes the cosine similarity in Doc2Vec\n",
        "    score = model.n_similarity(sent_a_split[i],sent_b_split[i])\n",
        "    doc2vec_scores.append(score)\n",
        "print(doc2vec_scores)"
      ],
      "metadata": {
        "id": "kaIV91fkbPn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# words = model.wv.vocab\n",
        "# print(model.wv['war'])"
      ],
      "metadata": {
        "id": "vvsWfbDlnnXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.hist(doc2vec_scores, bins = 200)\n",
        "plt.xlim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6bWImxdGc9QL",
        "outputId": "d42dfe66-afa1-48fb-ebe5-86b100861215"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ind=5635            \n",
        "# print(str(sent_a_split[ind])+\" \"+ str(sent_b_split[ind])+\" \"+ str(doc2vec_scores[ind]))"
      ],
      "metadata": {
        "id": "UYBaGsEuuycY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(doc2vec_scores)):\n",
        "#   if doc2vec_scores[i]<0.6:\n",
        "#     print(str(i)+\" \"+str(doc2vec_scores[i]))"
      ],
      "metadata": {
        "id": "wws7r0SmrHr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sent_a_split_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laIKGg-QEAAY",
        "outputId": "b35d6c85-93c3-4c73-909f-ff1deeb3cbc7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1379"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_vect_all=[]\n",
        "sent_vect=[]\n",
        "for j in range(len(sent_a_split)):\n",
        "  sent_vect=[]\n",
        "  for i in model.infer_vector(sent_a_split[j], steps=20):\n",
        "    sent_vect.append(i)\n",
        "  for i in model.infer_vector(sent_b_split[j], steps=20):\n",
        "    sent_vect.append(i)\n",
        "  sent_vect_all.append(np.array(sent_vect))"
      ],
      "metadata": {
        "id": "svOhVX-N1oUR"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_vect_all_test=[]\n",
        "sent_vect=[]\n",
        "for j in range(len(sent_a_split_test)):\n",
        "  sent_vect=[]\n",
        "  for i in model.infer_vector(sent_a_split_test[j], steps=20):\n",
        "    sent_vect.append(i)\n",
        "  for i in model.infer_vector(sent_b_split_test[j], steps=20):\n",
        "    sent_vect.append(i)\n",
        "  sent_vect_all_test.append(np.array(sent_vect))"
      ],
      "metadata": {
        "id": "kbeWAr4HCSuG"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sent_vect_all_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnj3NdRiDoD5",
        "outputId": "e9d1a01f-6892-4197-950b-160b1819858e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, x_train = data_train['score'],sent_vect_all\n"
      ],
      "metadata": {
        "id": "RjdJIoQ_OFkp"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test, x_test = data_test['score'],sent_vect_all_test\n"
      ],
      "metadata": {
        "id": "-hE22W_WEuej"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((y_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDH1br30R9OI",
        "outputId": "2e438cbf-b1de-421d-8a72-5dc30f401ba8"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "y=regr.fit(x_train, y_train)\n",
        "from scipy.stats import spearmanr\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEIxoVLhR7oR",
        "outputId": "553d2dc7-bb78-42a6-9b7a-2cda8ea2dff1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=y.predict(x_train)"
      ],
      "metadata": {
        "id": "yA7dj8GGTDOh"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_test=y.predict(x_test)"
      ],
      "metadata": {
        "id": "cWaK_HHrFSJb"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ypred)\n",
        "coef, p = spearmanr(ypred, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jxajRAgTekd",
        "outputId": "e23388d5-2d9d-4664-cdb5-90342954a872"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.3011317 2.582101  2.6548836 ... 2.3955631 1.7887527 2.1720605]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ypred_test)\n",
        "coeft, pt = spearmanr(ypred_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Emh99vFYyp",
        "outputId": "c9ccb720-f0ef-43ed-b16f-cc4c8a004d52"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.3669887 2.9471078 2.522016  ... 2.1276805 2.5244892 2.618916 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(coef)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFBr5CKgTw24",
        "outputId": "ef188f21-591a-470d-e27b-32e94faaf66e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3053522208534316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(coeft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP8Jdf9YFwRT",
        "outputId": "03f66317-479b-4a8b-f26f-b95ffa7a5b02"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1463310661660234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jkasdbjksdhjasd"
      ],
      "metadata": {
        "id": "CisW8rnYHa8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_train=data_test\n",
        "\n",
        "list1=[]\n",
        "list2=[]\n",
        "for i in data_train['sent_a']:\n",
        "  list1.append(review_to_wordlist(i))\n",
        "data_train['sent_a']=list1\n",
        "for i in data_train['sent_b']:\n",
        "  list2.append(review_to_wordlist(i))\n",
        "data_train['sent_b']=list2\n",
        "\n",
        "\n",
        "\n",
        "# Contains the processed questions for Doc2Vec\n",
        "sent_labeled = []\n",
        "\n",
        "for i in range(len(data_train['sent_a'])):\n",
        "    # Question strings need to be separated into words\n",
        "    # Each question needs a unique label\n",
        "    sent_labeled.append(LabeledSentence(data_train['sent_a'][i].split(), data_train[data_train.index == i].id))\n",
        "    sent_labeled.append(LabeledSentence(data_train['sent_b'][i].split(), data_train[data_train.index == i].id))\n",
        "\n",
        "\n",
        "sent_a_split = []\n",
        "for sentence in data_train['sent_a']:\n",
        "    sent_a_split.append(sentence.split())\n",
        "    \n",
        "sent_b_split = []\n",
        "for sentence in data_train['sent_b']:\n",
        "    sent_b_split.append(sentence.split())\n",
        "\n",
        "\n",
        "model.build_vocab(sent_labeled)\n",
        "model.train(sent_labeled, total_examples=model.corpus_count, epochs=50)\n",
        "\n",
        "\n",
        "\n",
        "sent_vect_all=[]\n",
        "sent_vect=[]\n",
        "for j in range(len(sent_a_split)):\n",
        "  sent_vect=[]\n",
        "  for i in model.infer_vector(sent_a_split[j], steps=20):\n",
        "    sent_vect.append(i)\n",
        "  for i in model.infer_vector(sent_b_split[j], steps=20):\n",
        "    sent_vect.append(i)\n",
        "  sent_vect_all.append(np.array(sent_vect))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "660KawY8uq1b",
        "outputId": "d21b7b86-25af-40f9-eee8-f484394eef33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, x_train = data_train['score'],sent_vect_all"
      ],
      "metadata": {
        "id": "mgjVm95Nuq-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sent_a_split:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "lVB6dHnxva6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=y.predict(x_train)"
      ],
      "metadata": {
        "id": "ar_eYPsgva9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ypred)\n",
        "coef, p = spearmanr(ypred, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLL9pYz5vbAv",
        "outputId": "759a4b02-1a6c-4821-dcdb-b7b57fbe7713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.5551026 2.477893  2.2829757 ... 2.7419739 2.3035533 2.5714786]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(coef)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuhZK2cFvbD6",
        "outputId": "fb24e2fe-d3bd-492e-8efb-3d20cf857f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11573511188241879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j1_Izh5kvbHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "StRhSIlmvbKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfggddfhdfhdfh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "4iwEF4uFvbNz",
        "outputId": "b5aa72b1-8109-4f8d-faa3-63771b7afcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-289-33c336d54107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfggddfhdfhdfh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dfggddfhdfhdfh' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "g2Cp9QPKZ8hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "7Tzc5hhEeiPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_tensor_all=[]\n",
        "segments_tensors_all=[]\n",
        "both_sent_data=[]\n",
        "#concatinating both senta and sentb columns, total elements = 5749*2\n",
        "for i in data_train['sent_a']: \n",
        "  both_sent_data.append(i)\n",
        "for i in data_train['sent_a']: \n",
        "  both_sent_data.append(i)\n",
        "\n",
        "\n",
        "\n",
        "for i in both_sent_data: \n",
        "  text = i\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "  # Tokenize our sentence with the BERT tokenizer.\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "  segments_ids = [1] * len(tokens_tensor[0])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  print(tokens_tensor)\n",
        "  print(segments_tensors)\n",
        "  tokens_tensor_all.append(tokens_tensor)\n",
        "  segments_tensors_all.append(segments_tensors)\n",
        "  # Print out the tokens.\n",
        "  # print (tokenized_text)"
      ],
      "metadata": {
        "id": "apdIPloketO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "gfYRQvg-gNTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers.\n",
        "hidden_states_all=[]\n",
        "for i in range(len(tokens_tensor_all)):\n",
        "  with torch.no_grad():\n",
        "\n",
        "      outputs = model(tokens_tensor_all[i], segments_tensors_all[i])\n",
        "\n",
        "      # Evaluating the model will return a different number of objects based on \n",
        "      # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "      # becase we set `output_hidden_states = True`, the third item will be the \n",
        "      # hidden states from all layers. See the documentation for more details:\n",
        "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "      hidden_states = outputs[2]\n",
        "      hidden_states_all.append(hidden_states)"
      ],
      "metadata": {
        "id": "yizahRDPgaiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings_all=[]\n",
        "for i in hidden_states_all:\n",
        "\n",
        "  token_embeddings = torch.stack(i, dim=0)\n",
        "  token_embeddings_all.append(token_embeddings)\n",
        "\n",
        "  # token_embeddings.size()"
      ],
      "metadata": {
        "id": "I57HAvdNh8Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings.size()"
      ],
      "metadata": {
        "id": "Ud6zdWXns58O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove dimension 1, the \"batches\".\n",
        "temp=[]\n",
        "for i in token_embeddings_all:\n",
        "  token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "  temp.append(token_embeddings)\n",
        "token_embeddings_all=temp\n",
        "# token_embeddings.size()"
      ],
      "metadata": {
        "id": "LLiroyeBiLPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Swap dimensions 0 and 1.\n",
        "temp=[]\n",
        "for i in token_embeddings_all:\n",
        "  token_embeddings = token_embeddings.permute(1,0,2)\n",
        "  temp.append(token_embeddings)\n",
        "token_embeddings_all=temp\n",
        "# token_embeddings.size()"
      ],
      "metadata": {
        "id": "jiRKNNcLiO43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stores the token vectors, with shape [22 x 3,072]\n",
        "token_vecs_cat_all=[]\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for i in token_embeddings_all:\n",
        "  token_vecs_cat = []\n",
        "  for token in i:\n",
        "      \n",
        "      # `token` is a [12 x 768] tensor\n",
        "\n",
        "      # Concatenate the vectors (that is, append them together) from the last \n",
        "      # four layers.\n",
        "      # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "      cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "      \n",
        "      # Use `cat_vec` to represent `token`.\n",
        "      token_vecs_cat.append(cat_vec)\n",
        "  token_vecs_cat_all.append(token_vecs_cat)\n",
        "\n",
        "  print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "metadata": {
        "id": "61X1MavKijHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stores the token vectors, with shape [22 x 768]\n",
        "token_vecs_cat_all = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for i in token_embeddings_all:\n",
        "  token_vecs_cat = []\n",
        "  for token in i:\n",
        "\n",
        "      # `token` is a [12 x 768] tensor\n",
        "\n",
        "      # Sum the vectors from the last four layers.\n",
        "      cat_vec = torch.sum(token[-4:], dim=0)\n",
        "      \n",
        "      # Use `sum_vec` to represent `token`.\n",
        "      token_vecs_cat.append(cat_vec)\n",
        "  token_vecs_cat_all.append(token_vecs_cat)\n",
        "\n",
        "  print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "metadata": {
        "id": "pbgWldLmodq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "for i in hidden_states_all:\n",
        "  token_vecs = i[-2][0]\n",
        "\n",
        "  # Calculate the average of all 22 token vectors.\n",
        "  sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "metadata": {
        "id": "Ni8r7Rqernnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
      ],
      "metadata": {
        "id": "32THw4lIsaRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)"
      ],
      "metadata": {
        "id": "-RxnRJIci4ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('First 5 vector values for each instance of any word.')\n",
        "print('')\n",
        "print(token_vecs_cat)\n"
      ],
      "metadata": {
        "id": "q9GOWQe_jJey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(token_vecs_cat_all),len(data_train['sent_a']))"
      ],
      "metadata": {
        "id": "bE-_9xQnwzXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(token_embeddings_all)):\n",
        "  temp_vec=[]\n",
        "  for token in token_embeddings_all[i]:\n",
        "    for j in token.tolist():\n",
        "      temp_vec.append(j)\n",
        "  token_embeddings_all[i]=temp_vec"
      ],
      "metadata": {
        "id": "smkePqQB1se1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_a_token_vecs_all=[]\n",
        "sent_b_token_vecs_all=[]\n",
        "for i in range(5749):\n",
        "  sent_a_token_vecs_all.append(token_vecs_cat_all[i])\n",
        "for i in range(5749,5749*2):\n",
        "  sent_b_token_vecs_all.append(token_vecs_cat_all[i])\n",
        "print(len(sent_a_token_vecs_all),len(sent_b_token_vecs_all))\n",
        "\n"
      ],
      "metadata": {
        "id": "qKMemMjax8Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_vects_concat_all=[]\n",
        "for i in range(5749):\n",
        "  for j in sent_a_token_vecs_all[i]:\n",
        "    sent_vects_concat_all.append(j)\n",
        "  for k in sent_b_token_vecs_all[i]:\n",
        "    sent_vects_concat_all.append(k)"
      ],
      "metadata": {
        "id": "tSp_br0iyCKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, x_train = data_train['score'],sent_vects_concat_all\n",
        "\n"
      ],
      "metadata": {
        "id": "op_nYK8M0WHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "y=regr.fit(x_train, y_train)\n",
        "from scipy.stats import spearmanr\n",
        "print()"
      ],
      "metadata": {
        "id": "8pCOTj9x0eyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=y.predict(x_train)"
      ],
      "metadata": {
        "id": "JeEe40kh0fHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ypred)\n",
        "coef, p = spearmanr(ypred, y_train)"
      ],
      "metadata": {
        "id": "bqLurwFe0nV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(coef)"
      ],
      "metadata": {
        "id": "DsSS31Hg0nZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}