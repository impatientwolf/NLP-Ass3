{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mske80S67Zlm"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "\n",
        "# Kindly add all your installations and versions if any in this cell."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import csv\n",
        "from scipy import stats\n",
        "from sklearn import linear_model\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ],
      "metadata": {
        "id": "vphxW0e_8Uza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66e918f-236f-4db0-a9c9-aa240d51791d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH=\"drive/MyDrive/NLP Ass3 stsbenchmark/\"\n",
        "def read_sts_csv(dataset_type=\"train\", columns=['source', 'type', 'year', 'id', 'score', 'sent_a', 'sent_b']):\n",
        "  path = INPUT_PATH + \"sts-\"+ dataset_type + \".csv\"\n",
        "  return pd.read_csv(path,sep=\"\\t\",header=None, names=columns,quoting=csv.QUOTE_NONE)\n",
        "\n",
        "data_train = read_sts_csv(\"train\") # create the train, dev and test dataframes\n",
        "data_dev = read_sts_csv(\"dev\") # create the train, dev and test dataframes\n",
        "data_test = read_sts_csv(\"test\") # create the train, dev and test dataframes\n"
      ],
      "metadata": {
        "id": "20F3h1rj8U2X"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartModel\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "model = BartModel.from_pretrained('facebook/bart-base')\n"
      ],
      "metadata": {
        "id": "StRhSIlmvbKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"hi my\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state"
      ],
      "metadata": {
        "id": "mOm6ZUS7aToU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_states.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdWpt2ncZfxC",
        "outputId": "8e765aa2-cf61-4ad9-bbc6-43bd6c690c02"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_a_tensor_train=[]\n",
        "for i in data_train['sent_a']:\n",
        "  input = tokenizer(i, return_tensors=\"pt\")\n",
        "  output = model(**inputs)\n",
        "  hidden_state = outputs.last_hidden_state\n",
        "  sent_a_tensor_train.append(hidden_state)\n",
        "\n",
        "sent_b_tensor_train=[]\n",
        "for i in data_train['sent_b']:\n",
        "  input = tokenizer(i, return_tensors=\"pt\")\n",
        "  output = model(**inputs)\n",
        "  hidden_state = outputs.last_hidden_state\n",
        "  sent_a_tensor_train.append(hidden_state)\n"
      ],
      "metadata": {
        "id": "yizahRDPgaiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_a_tensor_dev=[]\n",
        "for i in data_dev['sent_a']:\n",
        "  input = tokenizer(i, return_tensors=\"pt\")\n",
        "  output = model(**inputs)\n",
        "  hidden_state = outputs.last_hidden_state\n",
        "  sent_a_tensor_dev.append(hidden_state)\n",
        "\n",
        "sent_b_tensor_dev=[]\n",
        "for i in data_dev['sent_b']:\n",
        "  input = tokenizer(i, return_tensors=\"pt\")\n",
        "  output = model(**inputs)\n",
        "  hidden_state = outputs.last_hidden_state\n",
        "  sent_b_tensor_dev.append(hidden_state)\n"
      ],
      "metadata": {
        "id": "p3PLrc4KdLB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_a_tensor_test=[]\n",
        "for i in data_test['sent_a']:\n",
        "  input = tokenizer(i, return_tensors=\"pt\")\n",
        "  output = model(**inputs)\n",
        "  hidden_state = outputs.last_hidden_state\n",
        "  sent_a_tensor_test.append(hidden_state)\n",
        "\n",
        "sent_b_tensor_test=[]\n",
        "for i in data_test['sent_b']:\n",
        "  input = tokenizer(i, return_tensors=\"pt\")\n",
        "  output = model(**inputs)\n",
        "  hidden_state = outputs.last_hidden_state\n",
        "  sent_b_tensor_test.append(hidden_state)\n"
      ],
      "metadata": {
        "id": "UqQC_XuDdLE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Concatenate the tensors for all layers. We use `stack` here to\n",
        "# # create a new dimension in the tensor.\n",
        "# token_embeddings_all=[]\n",
        "# for i in hidden_states_all:\n",
        "\n",
        "#   token_embeddings = torch.stack(i, dim=0)\n",
        "#   token_embeddings_all.append(token_embeddings)\n",
        "\n",
        "#   # token_embeddings.size()"
      ],
      "metadata": {
        "id": "I57HAvdNh8Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings.size()"
      ],
      "metadata": {
        "id": "Ud6zdWXns58O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Remove dimension 1, the \"batches\".\n",
        "# temp=[]\n",
        "# for i in token_embeddings_all:\n",
        "#   token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "#   temp.append(token_embeddings)\n",
        "# token_embeddings_all=temp\n",
        "# # token_embeddings.size()"
      ],
      "metadata": {
        "id": "LLiroyeBiLPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Swap dimensions 0 and 1.\n",
        "# temp=[]\n",
        "# for i in token_embeddings_all:\n",
        "#   token_embeddings = token_embeddings.permute(1,0,2)\n",
        "#   temp.append(token_embeddings)\n",
        "# token_embeddings_all=temp\n",
        "# # token_embeddings.size()"
      ],
      "metadata": {
        "id": "jiRKNNcLiO43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stores the token vectors, with shape [22 x 3,072]\n",
        "token_vecs_cat_all=[]\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for i in sent_a_tensor_train:\n",
        "  token_vecs_cat = []\n",
        "  for token in i:\n",
        "      \n",
        "      # `token` is a [12 x 768] tensor\n",
        "\n",
        "      # Concatenate the vectors (that is, append them together) from the last \n",
        "      # four layers.\n",
        "      # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "      cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "      \n",
        "      # Use `cat_vec` to represent `token`.\n",
        "      token_vecs_cat.append(cat_vec)\n",
        "  token_vecs_cat_all.append(token_vecs_cat)\n",
        "\n",
        "  print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "metadata": {
        "id": "61X1MavKijHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Stores the token vectors, with shape [22 x 768]\n",
        "# token_vecs_cat_all = []\n",
        "\n",
        "# # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# # For each token in the sentence...\n",
        "# for i in token_embeddings_all:\n",
        "#   token_vecs_cat = []\n",
        "#   for token in i:\n",
        "\n",
        "#       # `token` is a [12 x 768] tensor\n",
        "\n",
        "#       # Sum the vectors from the last four layers.\n",
        "#       cat_vec = torch.sum(token[-4:], dim=0)\n",
        "      \n",
        "#       # Use `sum_vec` to represent `token`.\n",
        "#       token_vecs_cat.append(cat_vec)\n",
        "#   token_vecs_cat_all.append(token_vecs_cat)\n",
        "\n",
        "#   print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "metadata": {
        "id": "pbgWldLmodq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "for i in hidden_states_all:\n",
        "  token_vecs = i[-2][0]\n",
        "\n",
        "  # Calculate the average of all 22 token vectors.\n",
        "  sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "metadata": {
        "id": "Ni8r7Rqernnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
      ],
      "metadata": {
        "id": "32THw4lIsaRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)"
      ],
      "metadata": {
        "id": "-RxnRJIci4ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('First 5 vector values for each instance of any word.')\n",
        "print('')\n",
        "print(token_vecs_cat)\n"
      ],
      "metadata": {
        "id": "q9GOWQe_jJey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(token_vecs_cat_all),len(data_train['sent_a']))"
      ],
      "metadata": {
        "id": "bE-_9xQnwzXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(token_embeddings_all)):\n",
        "  temp_vec=[]\n",
        "  for token in token_embeddings_all[i]:\n",
        "    for j in token.tolist():\n",
        "      temp_vec.append(j)\n",
        "  token_embeddings_all[i]=temp_vec"
      ],
      "metadata": {
        "id": "smkePqQB1se1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_a_token_vecs_all=[]\n",
        "sent_b_token_vecs_all=[]\n",
        "for i in range(5749):\n",
        "  sent_a_token_vecs_all.append(token_vecs_cat_all[i])\n",
        "for i in range(5749,5749*2):\n",
        "  sent_b_token_vecs_all.append(token_vecs_cat_all[i])\n",
        "print(len(sent_a_token_vecs_all),len(sent_b_token_vecs_all))\n",
        "\n"
      ],
      "metadata": {
        "id": "qKMemMjax8Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_vects_concat_all=[]\n",
        "for i in range(5749):\n",
        "  for j in sent_a_token_vecs_all[i]:\n",
        "    sent_vects_concat_all.append(j)\n",
        "  for k in sent_b_token_vecs_all[i]:\n",
        "    sent_vects_concat_all.append(k)"
      ],
      "metadata": {
        "id": "tSp_br0iyCKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, x_train = data_train['score'],sent_vects_concat_all\n",
        "\n"
      ],
      "metadata": {
        "id": "op_nYK8M0WHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "y=regr.fit(x_train, y_train)\n",
        "from scipy.stats import spearmanr\n",
        "print()"
      ],
      "metadata": {
        "id": "8pCOTj9x0eyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=y.predict(x_train)"
      ],
      "metadata": {
        "id": "JeEe40kh0fHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ypred)\n",
        "coef, p = spearmanr(ypred, y_train)"
      ],
      "metadata": {
        "id": "bqLurwFe0nV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(coef)"
      ],
      "metadata": {
        "id": "DsSS31Hg0nZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}