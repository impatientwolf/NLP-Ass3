{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A-g0i4MkbpUM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "from csv import writer\n",
        "from urllib.request import Request,urlopen\n",
        "# !pip install requests-html\n",
        "# from requests_html import HTMLSession,AsyncHTMLSession\n",
        "# !pip3 install nest_asyncio\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "# !wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -\n",
        "# !echo 'deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main' | sudo tee /etc/apt/sources.list.d/google-chrome.list\n",
        "# !sudo apt update \n",
        "# !sudo apt install google-chrome-stable\n",
        "# !ldd ~/.local/share/pyppeteer/local-chromium/588429/chrome-linux/chrome | grep 'not found'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from http.client import HTTPException\n",
        "from pyppeteer.errors import BrowserError\n",
        "import pyppeteer.launcher\n",
        "import time\n",
        "from urllib.error import URLError\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def get_ws_endpoint(url) -> str:\n",
        "    url = url + '/json/version'\n",
        "    timeout = time.time() + 30\n",
        "    while True:\n",
        "        if time.time() > timeout:\n",
        "            raise BrowserError('Browser closed unexpectedly:\\n')\n",
        "        try:\n",
        "            with urlopen(url) as f:\n",
        "                data = json.loads(f.read().decode())\n",
        "            break\n",
        "        except (URLError, HTTPException) as e:\n",
        "            pass\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    return data['webSocketDebuggerUrl']\n",
        "\n",
        "\n",
        "pyppeteer.launcher.get_ws_endpoint = get_ws_endpoint"
      ],
      "metadata": {
        "id": "QldyBcZ3qeTS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "6c8ea117-ef2f-4dc2-8ddc-1b7085bc5b54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-151a7739b2dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyppeteer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrowserError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyppeteer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyppeteer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22Dentist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\"\n",
        "\n",
        "asession=AsyncHTMLSession()\n",
        "\n",
        "async def afunc():\n",
        "  \n",
        "  page=await asession.get(url)\n",
        "  await page.html.arender(timeout=50)\n",
        "  return page\n",
        "page=asession.run(afunc)\n",
        "# lists=[]\n",
        "\n",
        "# soup=BeautifulSoup(page.text,\"html.parser\")\n",
        "# lists=soup.find_all('div',class_=\"info-section\")\n",
        "# for i in lists:\n",
        "  \n",
        "#   print(i.find('a')['href'])\n",
        "# next=soup.find('div',class_=\"pure-u-14-24\")\n",
        "# .find('ul',class_=\"c-paginator\")\n",
        "\n",
        "# select_one(\"a:nth-of-type(4)\").text\n",
        "\n",
        "# print(next)"
      ],
      "metadata": {
        "id": "SFYKIOIgEpCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://www.practo.com/delhi/doctor/dr-anurag-ahuja-dentist-1/info?practice_id=1141246&specialization=Dentist&referrer=doctor_listing\"\n",
        "url=\"https://www.practo.com//delhi/doctor/shreya-krishna-dentist?practice_id=1353928&specialization=Dentist&referrer=doctor_listing\"\n",
        "page=requests.get(url)\n",
        "lists=[]\n",
        "\n",
        "soup=BeautifulSoup(page.content,\"html.parser\")\n",
        "name=soup.find('h1', class_=\"c-profile__title\").text\n",
        "qual=soup.find('p', class_=\"c-profile__details\").text\n",
        "spl=soup.find('div', class_=\"u-d-inline-flex\").text\n",
        "\n",
        "exp=soup.find('div',class_=\"c-profile__details\")\n",
        "# print(exp.select_one(\"h2:nth-of-type(4)\"))\n",
        "exp=exp.select_one(\"h2:nth-of-type(4)\")\n",
        "\n",
        "\n",
        "upvote_perc=soup.find('span', class_=\"u-green-text\")\n",
        "fee=soup.find('span', class_=\"u-f-right u-large-font u-bold u-valign--middle u-lheight-normal\").text\n",
        "# print(name,qual,spl,exp,upvote_perc,fee)\n",
        "\n",
        "lists=soup.find_all('div', class_=\"c-profile--clinic--item\")\n",
        "location=[]\n",
        "\n",
        "timing=[]\n",
        "temp=[]\n",
        "loctim=[]\n",
        "\n",
        "for i in lists:\n",
        "  if i.find('div', class_=\"c-profile--clinic--item\")!=None:\n",
        "    temp.append(i.find('div', class_=\"c-profile--clinic--item\"))\n",
        "for i in temp:\n",
        "  location.append(i.find('h4',class_=\"c-profile--clinic__location\").text)\n",
        "  days=i.find_all('p', class_=\"timings__days\")\n",
        "  time=i.find_all('p', class_=\"timings__time\")\n",
        "  # print(days)\n",
        "  # print(time)\n",
        "  if (len(days)>0 and len(time)>0):\n",
        "    for j, k in zip(days,time):\n",
        "      timing.append([j.text,k.text])\n",
        "    loctim.append([i.find('h4',class_=\"c-profile--clinic__location\").text,[j.text,k.text]])\n",
        "print(loctim)\n",
        "  # timing.append(i.find('div', class_= \"pure-u-1-3 u-cushion--left\").text)\n",
        "  \n",
        "revlists=soup.find_all('div',class_=\"pure-u-22-24 u-lheight-default\")\n",
        "reviews=[]\n",
        "for i in revlists:\n",
        "  Dict={}\n",
        "  typeofc=i.find('span',class_=\"u-blue-2-background u-smallest-font u-color--white u-round-corner--12 u-cushion--right-less u-cushion--small-left u-cushion--small-top u-cushion--small-bottom\").text\n",
        "  titleofc=i.find('span',class_=\"procedure\").text\n",
        "  # print(titleofc)\n",
        "  temp=i.find_all('span',class_=\"feedback__context\")\n",
        "  keywords=[]\n",
        "  for j in temp:\n",
        "    keywords.append(j.text)\n",
        "  review=i.find('p',class_=\"feedback__content u-large-font u-d-inline\").text\n",
        "  voteofc=i.find('div',class_=\"u-cushion--small-bottom u-large-font\").text\n",
        "  Dict['typeofc']=typeofc\n",
        "  Dict['titleofc']=titleofc\n",
        "  Dict['voteofc']=voteofc\n",
        "  Dict['keywords']=keywords\n",
        "  Dict['review']=review\n",
        "  reviews.append(Dict)\n",
        "with open('doctor.csv', 'w', encoding='utf8', newline='') as f:\n",
        "    wrt = writer(f)\n",
        "    header = ['Name', 'Qualification', 'Speciality', 'Experience',\"Fee\",\"Upvote Percentage\",\"Location and Timings\",\"Type of Consultation\",\"Topic Of Consultation\",\"Vote\",\"Keywords\",\"Review\"]\n",
        "    wrt.writerow(header)\n",
        "    \n",
        "    for i in reviews:\n",
        "      # print()\n",
        "      info=[name,qual,spl,exp,fee,upvote_perc,loctim,i['typeofc'],i['titleofc'],i['voteofc'],i['keywords'],i['review']]\n",
        "      wrt.writerow(info)\n"
      ],
      "metadata": {
        "id": "n83r81oObzoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from csv import writer\n",
        "# from urllib.request import Request,urlopen\n",
        "from requests_html import HTMLSession,AsyncHTMLSession\n",
        "\n",
        "def get_details(doctor_page):\n",
        "    lists=[]\n",
        "    soup=BeautifulSoup(doctor_page.text,\"html.parser\")\n",
        "    name=soup.find('h1', class_=\"c-profile__title\")\n",
        "    qual=soup.find('p', class_=\"c-profile__details\")\n",
        "    spl=soup.find('div', class_=\"u-d-inline-flex\")\n",
        "\n",
        "    exp=soup.find('div',class_=\"c-profile__details\")\n",
        "\n",
        "    if(exp!=None):\n",
        "        # exp=exp.select_one(\"h2:nth-of-type(3)\")\n",
        "        # print(exp.text)\n",
        "        exp = re.findall(r'\\d+', str(exp.text))[0]\n",
        "        # print(exp)\n",
        "\n",
        "    upvote_perc=soup.find('span', class_=\"u-green-text\")\n",
        "    fee=soup.find('span', class_=\"u-f-right u-large-font u-bold u-valign--middle u-lheight-normal\")\n",
        "    # # print(name,qual,spl,exp,upvote_perc,fee)\n",
        "    #\n",
        "    lists=soup.find_all('div', class_=\"c-profile--clinic--item\")\n",
        "    location=[]\n",
        "\n",
        "    timing=[]\n",
        "    temp=[]\n",
        "    loctim=[]\n",
        "\n",
        "    for i in lists:\n",
        "        if i.find('div', class_=\"c-profile--clinic--item\")!=None:\n",
        "            temp.append(i.find('div', class_=\"c-profile--clinic--item\"))\n",
        "    for i in temp:\n",
        "        location.append(i.find('h4',class_=\"c-profile--clinic__location\").text)\n",
        "        days=i.find_all('p', class_=\"timings__days\")\n",
        "        time=i.find_all('p', class_=\"timings__time\")\n",
        "\n",
        "        if len(days)>0 and len(time)>0:\n",
        "            for j, k in zip(days,time):\n",
        "                timing.append([j.text,k.text])\n",
        "            loctim.append([i.find('h4',class_=\"c-profile--clinic__location\").text,[j.text,k.text]])\n",
        "    # print(loctim)\n",
        "    # timing.append(i.find('div', class_= \"pure-u-1-3 u-cushion--left\").text)\n",
        "\n",
        "    revlists=soup.find_all('div',class_=\"pure-u-22-24 u-lheight-default\")\n",
        "    reviews=[]\n",
        "    for i in revlists:\n",
        "        Dict={}\n",
        "        typeofc=i.find('span',class_=\"u-blue-2-background u-smallest-font u-color--white u-round-corner--12 u-cushion--right-less u-cushion--small-left u-cushion--small-top u-cushion--small-bottom\")\n",
        "        titleofc=i.find('span',class_=\"procedure\")\n",
        "        # print(titleofc)\n",
        "        temp=i.find_all('span',class_=\"feedback__context\")\n",
        "        keywords=[]\n",
        "        for j in temp:\n",
        "            keywords.append(j.text)\n",
        "        review=i.find('p',class_=\"feedback__content u-large-font u-d-inline\")\n",
        "        voteofc=i.find('div',class_=\"u-cushion--small-bottom u-large-font\")\n",
        "\n",
        "        Dict['typeofc']=typeofc\n",
        "        Dict['titleofc']=titleofc\n",
        "        Dict['voteofc']=voteofc\n",
        "        Dict['keywords']=keywords\n",
        "        Dict['review']=review\n",
        "        reviews.append(Dict)\n",
        "    # print(name)\n",
        "    rows=[]\n",
        "    for i in reviews:\n",
        "\n",
        "        row=[name,qual,spl,fee,upvote_perc,i['typeofc'],i['titleofc'],i['voteofc'],i['review']]\n",
        "        for j in range(len(row)):\n",
        "            if row[j]!=None:\n",
        "                row[j]=row[j].text\n",
        "        row.insert(3,exp)\n",
        "        row.insert(6,loctim)\n",
        "        row.insert(10,i['keywords'])\n",
        "        rows.append(row)\n",
        "    return rows\n",
        "    # print([name,qual,spl,exp,fee,upvote_perc,loctim,reviews])\n",
        "    # return [name,qual,spl,exp,fee,upvote_perc,loctim,reviews]\n",
        "\n",
        "\n",
        "def write(rows):\n",
        "    with open('doctor.csv', 'a', encoding='utf8', newline='') as f:\n",
        "        wrt = writer(f)\n",
        "        # header = ['Name', 'Qualification', 'Speciality', 'Experience',\"Fee\",\"Upvote Percentage\",\"Location and Timings\",\"Type of Consultation\",\"Topic Of Consultation\",\"Vote\",\"Keywords\",\"Review\"]\n",
        "        # wrt.writerow(header)\n",
        "\n",
        "        for i in rows:\n",
        "            # print()\n",
        "            info=[]\n",
        "            for j in i:\n",
        "                info.append(j)\n",
        "            # info=[name,qual,spl,exp,fee,upvote_perc,loctim,i['typeofc'],i['titleofc'],i['voteofc'],i['keywords'],i['review']]\n",
        "            wrt.writerow(info)\n",
        "\n",
        "\n",
        "with open('doctor.csv', 'w', encoding='utf8', newline='') as f:\n",
        "    wrt = writer(f)\n",
        "    header = ['Name', 'Qualification', 'Speciality', 'Experience',\"Fee\",\"Upvote Percentage\",\"Location and Timings\",\"Type of Consultation\",\"Topic Of Consultation\",\"Vote\",\"Keywords\",\"Review\"]\n",
        "    wrt.writerow(header)\n",
        "\n",
        "\n",
        "urls=[\"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22Dentist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22Gynecologist%2Fobstetrician%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22Dermatologist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22Ear-nose-throat%20(ent)%20Specialist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22General%20Physician%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22orthopedist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22pediatrician%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22ophthalmologist%2F%20eye%20surgeon%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22cardiologist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22gastroenterologist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22nephrologist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22neurologist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22oncologist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22plastic%20surgeon%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22psychiatrist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22pulmonologist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22urologist%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\",\n",
        "     \"https://www.practo.com/search/doctors?results_type=doctor&q=%5B%7B%22word%22%3A%22Homoeopath%22%2C%22autocompleted%22%3Atrue%2C%22category%22%3A%22subspeciality%22%7D%5D&city=Delhi\"]\n",
        "count=[200,200,100,100,100,100,100,95,68,51,33,38,58,36,61,45,44,66]\n",
        "\n",
        "session=HTMLSession()\n",
        "for l in range(len(urls)):\n",
        "    url=urls[l]\n",
        "    for k in range(int(count[l]/10)):\n",
        "\n",
        "        page=session.get(url)\n",
        "        j=True\n",
        "        while(j):\n",
        "            try:\n",
        "                page.html.render(timeout=40)\n",
        "                j=False\n",
        "            except:\n",
        "                j=True\n",
        "\n",
        "        soup=BeautifulSoup(page.text,\"html.parser\")\n",
        "        lists=soup.find_all('div',class_=\"info-section\")\n",
        "        for i in lists:\n",
        "            link=\"https://www.practo.com/\"+i.find('a')['href']\n",
        "            print(link)\n",
        "            doctor_page=session.get(link)\n",
        "            # print(doctor_page)\n",
        "            rows=get_details(doctor_page)\n",
        "            write(rows)\n",
        "\n",
        "\n",
        "        print(page)\n",
        "        try:\n",
        "            pageno=page.html.find('ul.c-paginator',first=True).find('li')\n",
        "            next_url=list(pageno[11].absolute_links)[0]\n",
        "            url=next_url\n",
        "        except:\n",
        "\n",
        "            print(k,url)\n",
        "            continue"
      ],
      "metadata": {
        "id": "8w-LQIRL4W-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}